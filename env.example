# ============================================================================
# AI SERVICE ENVIRONMENT CONFIGURATION
# ============================================================================
# Copy this file to .env and configure your values

# ============================================================================
# APPLICATION SETTINGS
# ============================================================================
DEBUG=true
HOST=0.0.0.0
PORT=8000
LOG_LEVEL=INFO

# ============================================================================
# AI API KEYS (Required)
# ============================================================================
# Google Gemini API Keys (comma-separated for load balancing and high availability)
# Get your keys from: https://ai.google.dev/
# Example: GEMINI_KEYS=key1,key2,key3
GEMINI_KEYS=your_gemini_api_key_1,your_gemini_api_key_2,your_gemini_api_key_3

# OpenAI API Keys (optional, for future extensions)
# Get your keys from: https://platform.openai.com/api-keys
# OPENAI_KEYS=your_openai_key_1,your_openai_key_2

# ============================================================================
# VECTOR DATABASE SETTINGS
# ============================================================================
# Path where ChromaDB will store data (can be relative or absolute)
# For Docker: /app/data/vector_db
# For local: ./vector_db
VECTOR_DB_PATH=./vector_db

# ============================================================================
# AI MODELS CONFIGURATION
# ============================================================================
# Embedding model for document and query vectorization
# Recommended: Alibaba-NLP/gte-multilingual-base (good for Vietnamese)
EMBEDDING_MODEL=Alibaba-NLP/gte-multilingual-base

# Reranker model for improving search results accuracy
# Recommended: Alibaba-NLP/gte-multilingual-reranker-base
RERANKER_MODEL=Alibaba-NLP/gte-multilingual-reranker-base

# ============================================================================
# RAG PIPELINE SETTINGS
# ============================================================================
# Text chunking configuration for document processing
CHUNK_SIZE=1000
CHUNK_OVERLAP=100

# Retrieval configuration for RAG
MAX_RETRIEVAL_DOCS=10
RERANKER_TOP_K=3

# ============================================================================
# FILE UPLOAD SETTINGS
# ============================================================================
# Maximum file size in bytes (50MB = 50 * 1024 * 1024)
MAX_FILE_SIZE=52428800

# Allowed file types (comma-separated)
# Supported: PDF (PyMuPDF), DOCX, PPTX, Images (Gemini Vision)
ALLOWED_FILE_TYPES=pdf,docx,pptx,png,jpg,jpeg,gif,bmp,webp

# ============================================================================
# SECURITY SETTINGS
# ============================================================================
# API key for authentication (optional, leave empty to disable)
# Generate a strong random key for production
# API_KEY=your_super_secret_api_key_here

# CORS allowed origins (comma-separated)
# For development: *
# For production: https://yourdomain.com,https://app.yourdomain.com
CORS_ORIGINS=*

# ============================================================================
# EXAMPLE CONFIGURATIONS FOR DIFFERENT ENVIRONMENTS
# ============================================================================

# --- DEVELOPMENT ENVIRONMENT ---
# DEBUG=true
# LOG_LEVEL=DEBUG
# HOST=0.0.0.0
# PORT=8000
# CORS_ORIGINS=*
# VECTOR_DB_PATH=./vector_db

# --- PRODUCTION ENVIRONMENT ---
# DEBUG=false
# LOG_LEVEL=INFO
# HOST=0.0.0.0
# PORT=8000
# API_KEY=your_production_api_key_with_high_entropy
# CORS_ORIGINS=https://yourdomain.com,https://app.yourdomain.com
# VECTOR_DB_PATH=/app/data/vector_db

# --- DOCKER ENVIRONMENT ---
# HOST=0.0.0.0
# PORT=8000
# VECTOR_DB_PATH=/app/data/vector_db
# # Mount volume: -v /host/path/vector_db:/app/data/vector_db

# ============================================================================
# GETTING API KEYS
# ============================================================================

# üîë GOOGLE GEMINI API KEYS:
# 1. Go to https://ai.google.dev/
# 2. Click "Get API key in Google AI Studio"
# 3. Create a new project or select existing
# 4. Generate API key
# 5. For production, create multiple keys for load balancing

# üîë OPENAI API KEYS (Optional):
# 1. Go to https://platform.openai.com/api-keys
# 2. Create account or log in
# 3. Create new secret key
# 4. Copy and secure the key

# ============================================================================
# SECURITY BEST PRACTICES
# ============================================================================

# üîí PRODUCTION SECURITY:
# - Use strong API keys with proper rotation
# - Set specific CORS origins (not *)
# - Enable API_KEY authentication
# - Use HTTPS in production
# - Regularly monitor API usage
# - Keep dependencies updated

# üîí API KEY MANAGEMENT:
# - Never commit .env to version control
# - Use different keys for dev/staging/prod
# - Monitor API usage and set limits
# - Rotate keys regularly
# - Use environment variables in deployment

# ============================================================================
# TROUBLESHOOTING
# ============================================================================

# üêõ COMMON ISSUES:
# - Service won't start: Check GEMINI_KEYS configuration
# - Upload fails: Verify MAX_FILE_SIZE and ALLOWED_FILE_TYPES
# - No context found: Ensure documents are uploaded for the subject
# - Slow responses: Check embedding model loading and vector DB path
# - CORS errors: Update CORS_ORIGINS for your domain

# üêõ DEBUG MODE:
# Set DEBUG=true and LOG_LEVEL=DEBUG for detailed logging

# ============================================================================
# PERFORMANCE TUNING
# ============================================================================

# ‚ö° FOR BETTER PERFORMANCE:
# - Use SSD storage for VECTOR_DB_PATH
# - Increase MAX_RETRIEVAL_DOCS for better context (but slower)
# - Decrease CHUNK_SIZE for faster processing (but less context)
# - Use multiple GEMINI_KEYS for higher rate limits
# - Consider increasing MAX_FILE_SIZE for larger documents

# ‚ö° FOR MEMORY OPTIMIZATION:
# - Decrease CHUNK_SIZE and MAX_RETRIEVAL_DOCS
# - Use lighter embedding models
# - Limit concurrent file uploads 