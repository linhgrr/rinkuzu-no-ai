"""
Image file loader using Gemini Vision API

Processes images using Google's Gemini multimodal capabilities to extract
text content, describe visual elements, and understand image context.
"""
import io
import base64
from typing import List, BinaryIO, Dict, Any, Optional
from PIL import Image
from loguru import logger

from app.core.interfaces.file_loader import FileLoader, DocumentChunk


class ImageLoader(FileLoader):
    """
    Image file loader using Gemini Vision for content extraction
    
    Features:
    - Text extraction from images (OCR)
    - Visual content description
    - Multi-language support
    - Educational content analysis
    - Chart/diagram interpretation
    """
    
    def __init__(self, ai_service=None):
        """
        Initialize image loader
        
        Args:
            ai_service: AI service instance for processing (will be injected)
        """
        self.ai_service = ai_service
        self.supported_extensions = ["png", "jpg", "jpeg", "gif", "bmp", "webp"]
        
        # Vietnamese prompts for educational content analysis
        self.analysis_prompts = {
            "ocr": """
            H√£y tr√≠ch xu·∫•t to√†n b·ªô vƒÉn b·∫£n c√≥ trong h√¨nh ·∫£nh n√†y m·ªôt c√°ch ch√≠nh x√°c nh·∫•t. 
            Bao g·ªìm:
            - Ti√™u ƒë·ªÅ, ƒë·ªÅ m·ª•c
            - N·ªôi dung ch√≠nh
            - C√¥ng th·ª©c to√°n h·ªçc (n·∫øu c√≥)
            - Ch√∫ th√≠ch, ghi ch√∫
            - B·∫•t k·ª≥ vƒÉn b·∫£n n√†o kh√°c
            
            Gi·ªØ nguy√™n ƒë·ªãnh d·∫°ng v√† c·∫•u tr√∫c c·ªßa vƒÉn b·∫£n.
            """,
            
            "content_analysis": """
            Ph√¢n t√≠ch n·ªôi dung gi√°o d·ª•c trong h√¨nh ·∫£nh n√†y v√† m√¥ t·∫£:
            1. Ch·ªß ƒë·ªÅ/m√¥n h·ªçc ch√≠nh
            2. C√°c kh√°i ni·ªám quan tr·ªçng
            3. Bi·ªÉu ƒë·ªì, s∆° ƒë·ªì (n·∫øu c√≥)
            4. C√¥ng th·ª©c, ph∆∞∆°ng tr√¨nh (n·∫øu c√≥)
            5. M·ªëi quan h·ªá gi·ªØa c√°c y·∫øu t·ªë
            
            Tr·∫£ l·ªùi b·∫±ng ti·∫øng Vi·ªát.
            """,
            
            "diagram_analysis": """
            N·∫øu h√¨nh ·∫£nh n√†y ch·ª©a bi·ªÉu ƒë·ªì, s∆° ƒë·ªì, ho·∫∑c h√¨nh minh h·ªça khoa h·ªçc:
            1. M√¥ t·∫£ lo·∫°i bi·ªÉu ƒë·ªì/s∆° ƒë·ªì
            2. C√°c th√†nh ph·∫ßn ch√≠nh
            3. M·ªëi quan h·ªá ƒë∆∞·ª£c th·ªÉ hi·ªán
            4. √ù nghƒ©a gi√°o d·ª•c
            5. D·ªØ li·ªáu ho·∫∑c th√¥ng tin s·ªë (n·∫øu c√≥)
            
            Tr·∫£ l·ªùi b·∫±ng ti·∫øng Vi·ªát.
            """
        }
    
    async def load(self, file_stream: BinaryIO, filename: str) -> List[DocumentChunk]:
        """
        Load and process image using Gemini Vision
        
        Args:
            file_stream: Image file stream
            filename: Name of the image file
            
        Returns:
            List of document chunks with extracted content
            
        Raises:
            ValueError: If image cannot be processed
        """
        try:
            logger.info(f"üñºÔ∏è Processing image with Gemini Vision: {filename}")
            
            # Read and validate image
            if hasattr(file_stream, 'read'):
                image_bytes = file_stream.read()
            else:
                image_bytes = file_stream
            
            # Validate image format
            try:
                image = Image.open(io.BytesIO(image_bytes))
                image_format = image.format
                image_size = image.size
                image_mode = image.mode
                
                logger.info(f"üì∏ Image info: {image_size[0]}x{image_size[1]} {image_format} {image_mode}")
            except Exception as e:
                raise ValueError(f"Invalid image format: {e}")
            
            # Check if AI service is available
            if not self.ai_service:
                logger.warning("AI service not available, creating basic image chunk")
                return self._create_basic_chunk(filename, image_bytes, image_format, image_size)
            
            chunks = []
            
            # 1. Extract text content (OCR)
            ocr_content = await self._extract_text_content(image_bytes, filename)
            if ocr_content:
                ocr_chunk = DocumentChunk(
                    content=ocr_content,
                    metadata={
                        "filename": filename,
                        "source_type": "image",
                        "chunk_type": "ocr_text",
                        "image_format": image_format,
                        "image_size": f"{image_size[0]}x{image_size[1]}",
                        "analysis_type": "text_extraction"
                    }
                )
                chunks.append(ocr_chunk)
            
            # 2. Analyze visual content
            content_analysis = await self._analyze_content(image_bytes, filename)
            if content_analysis:
                analysis_chunk = DocumentChunk(
                    content=content_analysis,
                    metadata={
                        "filename": filename,
                        "source_type": "image",
                        "chunk_type": "content_analysis",
                        "image_format": image_format,
                        "image_size": f"{image_size[0]}x{image_size[1]}",
                        "analysis_type": "visual_analysis"
                    }
                )
                chunks.append(analysis_chunk)
            
            # 3. Analyze diagrams/charts if present
            diagram_analysis = await self._analyze_diagrams(image_bytes, filename)
            if diagram_analysis:
                diagram_chunk = DocumentChunk(
                    content=diagram_analysis,
                    metadata={
                        "filename": filename,
                        "source_type": "image",
                        "chunk_type": "diagram_analysis",
                        "image_format": image_format,
                        "image_size": f"{image_size[0]}x{image_size[1]}",
                        "analysis_type": "diagram_analysis"
                    }
                )
                chunks.append(diagram_chunk)
            
            logger.info(f"‚úÖ Image processed: {filename} -> {len(chunks)} content chunks")
            
            if not chunks:
                # Fallback: create basic chunk
                return self._create_basic_chunk(filename, image_bytes, image_format, image_size)
            
            return chunks
            
        except Exception as e:
            logger.error(f"‚ùå Failed to process image {filename}: {e}")
            raise ValueError(f"Failed to process image file: {e}")
    
    async def _extract_text_content(self, image_bytes: bytes, filename: str) -> Optional[str]:
        """Extract text content using Gemini Vision OCR"""
        try:
            # Convert image to base64 for Gemini
            image_b64 = base64.b64encode(image_bytes).decode()
            
            # Use AI service to extract text
            response = await self.ai_service.process_with_image(
                prompt=self.analysis_prompts["ocr"],
                image_data=image_b64,
                image_format="auto"
            )
            
            if response.success and response.content.strip():
                logger.debug(f"üìù OCR extracted {len(response.content)} characters from {filename}")
                return response.content.strip()
            
            return None
            
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è OCR extraction failed for {filename}: {e}")
            return None
    
    async def _analyze_content(self, image_bytes: bytes, filename: str) -> Optional[str]:
        """Analyze visual content and educational elements"""
        try:
            # Convert image to base64 for Gemini
            image_b64 = base64.b64encode(image_bytes).decode()
            
            # Use AI service to analyze content
            response = await self.ai_service.process_with_image(
                prompt=self.analysis_prompts["content_analysis"],
                image_data=image_b64,
                image_format="auto"
            )
            
            if response.success and response.content.strip():
                logger.debug(f"üîç Content analysis completed for {filename}")
                return response.content.strip()
            
            return None
            
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Content analysis failed for {filename}: {e}")
            return None
    
    async def _analyze_diagrams(self, image_bytes: bytes, filename: str) -> Optional[str]:
        """Analyze diagrams, charts, and scientific illustrations"""
        try:
            # Convert image to base64 for Gemini
            image_b64 = base64.b64encode(image_bytes).decode()
            
            # Use AI service to analyze diagrams
            response = await self.ai_service.process_with_image(
                prompt=self.analysis_prompts["diagram_analysis"],
                image_data=image_b64,
                image_format="auto"
            )
            
            if response.success and response.content.strip():
                # Only include if it contains meaningful diagram analysis
                content = response.content.strip()
                if any(keyword in content.lower() for keyword in 
                      ["bi·ªÉu ƒë·ªì", "s∆° ƒë·ªì", "chart", "diagram", "graph", "b·∫£ng", "c√¥ng th·ª©c"]):
                    logger.debug(f"üìä Diagram analysis completed for {filename}")
                    return content
            
            return None
            
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Diagram analysis failed for {filename}: {e}")
            return None
    
    def _create_basic_chunk(self, filename: str, image_bytes: bytes, 
                          image_format: str, image_size: tuple) -> List[DocumentChunk]:
        """Create basic chunk when AI processing is not available"""
        basic_content = f"""
        H√¨nh ·∫£nh: {filename}
        ƒê·ªãnh d·∫°ng: {image_format}
        K√≠ch th∆∞·ªõc: {image_size[0]}x{image_size[1]} pixels
        
        [N·ªôi dung h√¨nh ·∫£nh c·∫ßn ƒë∆∞·ª£c ph√¢n t√≠ch b·∫±ng Gemini Vision]
        """
        
        chunk = DocumentChunk(
            content=basic_content.strip(),
            metadata={
                "filename": filename,
                "source_type": "image",
                "chunk_type": "basic_info",
                "image_format": image_format,
                "image_size": f"{image_size[0]}x{image_size[1]}",
                "analysis_type": "metadata_only",
                "requires_ai_processing": True
            }
        )
        
        return [chunk]
    
    def supports_file_type(self, file_extension: str) -> bool:
        """Check if this loader supports the file type"""
        return file_extension.lower() in self.supported_extensions
    
    def get_supported_extensions(self) -> List[str]:
        """Get list of supported file extensions"""
        return self.supported_extensions.copy()
    
    def set_ai_service(self, ai_service):
        """Set AI service for image processing"""
        self.ai_service = ai_service 