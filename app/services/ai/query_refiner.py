from __future__ import annotations

"""
QueryRefiner â€“ helper that removes noise (answer options, instructions, emojis, etc.)
from a raw user question so that the Vector Store receives a concise, highly-relevant
query for embedding search.

Example
-------
Input:
    Giáº£i thuáº­t nÃ o sau Ä‘Ã¢y xem xÃ©t Ä‘áº¿n Æ°á»›c lÆ°á»£ng tá»›i nÃºt Ä‘Ã­ch?
    Options:
    A. Depth-first search
    B. Best-first search
    C. A* search
    D. Greedy best-first search
Output:
    Thuáº­t toÃ¡n nÃ o xem xÃ©t Æ°á»›c lÆ°á»£ng (heuristic) tá»›i nÃºt Ä‘Ã­ch?

If the input is already short and clean, the output should be identical.
"""

from typing import Dict
from loguru import logger

from app.core.interfaces.ai_service import AIService, ChatMessage


class QueryRefiner:
    """Use LLM to produce a cleaner search query from a potentially noisy prompt."""

    SYSTEM_PROMPT: str = (
    "Báº¡n lÃ  má»™t chuyÃªn gia trong viá»‡c tinh chá»‰nh cÃ¢u há»i cá»§a ngÆ°á»i dÃ¹ng cho há»‡ thá»‘ng tÃ¬m kiáº¿m ngá»¯ nghÄ©a (semantic search). "
    "Nhiá»‡m vá»¥ cá»§a báº¡n lÃ  diá»…n giáº£i láº¡i cÃ¢u há»i thÃ´ cá»§a ngÆ°á»i dÃ¹ng thÃ nh má»™t cÃ¢u truy váº¥n ngáº¯n gá»n, rÃµ rÃ ng vÃ  trá»±c tiáº¿p, phÃ¹ há»£p Ä‘á»ƒ tÃ¬m kiáº¿m trong cÆ¡ sá»Ÿ dá»¯ liá»‡u vector.\n\n"
    "QUY Táº®C:\n"
    "1. Giá»¯ láº¡i Ã½ Ä‘á»‹nh cá»‘t lÃµi cá»§a cÃ¢u há»i.\n"
    "2. Loáº¡i bá» táº¥t cáº£ thÃ´ng tin nhiá»…u: cÃ¡c tÃ¹y chá»n tráº£ lá»i (vÃ­ dá»¥: A, B, C, D), hÆ°á»›ng dáº«n (vÃ­ dá»¥: 'HÃ£y chá»n cÃ¢u tráº£ lá»i Ä‘Ãºng'), cÃ¡c cÃ¢u chÃ o há»i, emoji, v.v.\n"
    "3. KHÃ”NG Ä‘Æ°á»£c tráº£ lá»i cÃ¢u há»i. Chá»‰ tinh chá»‰nh láº¡i cÃ¢u há»i.\n"
    "4. KHÃ”NG thÃªm báº¥t ká»³ lá»i giáº£i thÃ­ch hay Ä‘oáº¡n vÄƒn giá»›i thiá»‡u nÃ o. Chá»‰ tráº£ vá» duy nháº¥t cÃ¢u truy váº¥n Ä‘Ã£ Ä‘Æ°á»£c tinh chá»‰nh.\n"
    "5. Náº¿u cÃ¢u há»i Ä‘Ã£ Ä‘á»§ rÃµ rÃ ng vÃ  ngáº¯n gá»n, hÃ£y tráº£ vá» y nguyÃªn.\n"
    "6. Giá»¯ nguyÃªn ngÃ´n ngá»¯ cá»§a cÃ¢u há»i gá»‘c (vÃ­ dá»¥: náº¿u há»i báº±ng tiáº¿ng Viá»‡t, cÃ¢u truy váº¥n cÅ©ng pháº£i báº±ng tiáº¿ng Viá»‡t).\n\n"
    "VÃ Dá»¤:\n\n"
    "VÃ­ dá»¥ 1:\n"
    "Input: Giáº£i thuáº­t nÃ o sau Ä‘Ã¢y xem xÃ©t Ä‘áº¿n Æ°á»›c lÆ°á»£ng tá»›i nÃºt Ä‘Ã­ch? Options: A. Depth-first search B. Best-first search C. A* search D. Greedy best-first search\n"
    "Output: Thuáº­t toÃ¡n nÃ o xem xÃ©t Æ°á»›c lÆ°á»£ng heuristic tá»›i nÃºt Ä‘Ã­ch?\n\n"
    "VÃ­ dá»¥ 2:\n"
    "Input: RAG lÃ  gÃ¬?\n"
    "Output: RAG lÃ  gÃ¬?\n\n"
    "VÃ­ dá»¥ 3:\n"
    "Input: ad Æ¡i cho mÃ¬nh há»i lÃ m tháº¿ nÃ o Ä‘á»ƒ tá»‘i Æ°u hÃ³a mÃ´ hÃ¬nh ngÃ´n ngá»¯ lá»›n áº¡? cáº£m Æ¡n ad nhiá»u ðŸ˜˜\n"
    "Output: cÃ¡ch tá»‘i Æ°u hÃ³a mÃ´ hÃ¬nh ngÃ´n ngá»¯ lá»›n"
)

    def __init__(self, ai_service: AIService, cache_size: int = 256) -> None:  # noqa: D401
        """Create a new QueryRefiner.

        Args:
            ai_service: Instance of AIService (GeminiService) used to perform the refinement.
            cache_size: Maximum number of refined queries to keep in memory.
        """
        self.ai_service = ai_service
        self._cache_size = cache_size
        self._cache: Dict[int, str] = {}

    async def refine(self, raw_question: str) -> str:  # noqa: D401
        """Return a concise query string extracted from *raw_question*.

        If the LLM call fails for any reason, the original question is returned to guarantee
        that the pipeline continues to work.
        """
        cache_key = hash(raw_question)
        if cache_key in self._cache:
            return self._cache[cache_key]

        messages = [
            ChatMessage(role="system", content=self.SYSTEM_PROMPT),
            ChatMessage(role="user", content=raw_question),
        ]

        try:
            response = await self.ai_service.chat(messages, temperature=0.0)
            if response.success and response.content.strip():
                refined = response.content.strip()
                if len(self._cache) < self._cache_size:
                    self._cache[cache_key] = refined
                logger.info(f"ðŸ” Query refined from '{raw_question}' to '{refined}'")
                return refined
        except Exception as exc:  
            logger.warning("QueryRefiner failed; falling back to raw question: %s", exc)

        # Fallback to original question
        return raw_question 